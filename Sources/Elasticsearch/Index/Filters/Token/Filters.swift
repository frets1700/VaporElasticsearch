
import Foundation

/**
 A token filter of type asciifolding that converts alphabetic, numeric, and symbolic Unicode characters which are not in the first 127 ASCII characters (the "Basic Latin" Unicode block) into their ASCII equivalents, if one exists.
 
 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-asciifolding-tokenfilter.html)
 */
public struct ASCIIFoldingFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.asciiFolding
    
    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String
    
    public init() {
        self.name = self.type
    }
}

/**
 The apostrophe token filter strips all characters after an apostrophe, including the apostrophe itself.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-apostrophe-tokenfilter.html)
 */
public struct ApostropheFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.apostrophe

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 The classic token filter does optional post-processing of terms that are generated by the classic tokenizer.

 This filter removes the english possessive from the end of words, and it removes dots from acronyms.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-classic-tokenfilter.html)
 */
public struct ClassicFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.classic

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 The decimal digit token filter folds unicode digits to 0-9

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-decimal-digit-tokenfilter.html)
 */
public struct DecimalDigitFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.decimalDigit

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 The kstem token filter is a high performance filter for english. All terms must already be lowercased (use lowercase filter) for this filter to work correctly.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-kstem-tokenfilter.html)
 */
public struct KStemFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.kStem

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 A token filter of type porter_stem that transforms the token stream as per the Porter stemming algorithm.

 Note, the input to the stemming filter must already be in lower case, so you will need to use Lower Case Token Filter or Lower Case Tokenizer farther down the Tokenizer chain in order for this to work properly!. For example, when using custom analyzer, make sure the lowercase filter comes before the porter_stem filter in the list of filters.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-porterstem-tokenfilter.html)
 */
public struct PorterStemFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.porterStem

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 A token filter of type reverse that simply reverses each token.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-reverse-tokenfilter.html)
 */
public struct ReverseFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.reverse

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 A token filter of type standard that normalizes tokens extracted with the standard tokenizer.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-tokenfilter.html)
 */
public struct StandardFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.standard

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 The trim token filter trims the whitespace surrounding a token.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-trim-tokenfilter.html)
 */
public struct TrimFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.trim

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 A token filter of type uppercase that normalizes token text to upper case.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-uppercase-tokenfilter.html)
 */
public struct UppercaseFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.uppercase

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}

/**
 A token filter of type length that removes words that are too long or too short for the stream.

 [More information](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-length-tokenfilter.html)
 */
public struct LengthFilter: TokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.length

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    public let name: String
    public let min: Int
    public let max: Int

    enum CodingKeys: String, CodingKey {
        case type
        case min
        case max
    }

    public init(name: String, min: Int, max: Int) {
        self.name = name
        self.min = min
        self.max = max
    }

    /// :nodoc:
    public init(from decoder: Decoder) throws {
        let container = try decoder.container(keyedBy: CodingKeys.self)
        self.name = (decoder.codingPath.last?.stringValue)!

        self.min = try container.decode(Int.self, forKey: .min)
        self.max = try container.decode(Int.self, forKey: .max)
    }
}

public struct ScandinavianFoldingFilter: BasicTokenFilter, BuiltinTokenFilter {
    /// :nodoc:
    public static var typeKey = TokenFilterType.scandinavianFolding

    /// Holds the string that Elasticsearch uses to identify the filter type
    public let type = typeKey.rawValue
    /// :nodoc:
    public let name: String

    public init() {
        self.name = self.type
    }
}


